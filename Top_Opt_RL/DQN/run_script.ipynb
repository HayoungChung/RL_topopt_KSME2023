{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This is the main script to run the DQN algorithm. '''\n",
    "import os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(\"run_script.ipynb\"))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary modules\n",
    "from Top_Opt_RL.DQN.FEA_SOLVER_GENERAL import *\n",
    "from Top_Opt_RL.DQN.opts import parse_opts\n",
    "from Top_Opt_RL.DQN.TopOpt_Env_Functions import TopOpt_Gen, Prog_Refine_Act,User_Inputs,App_Inputs, Testing_Inputs, Testing_Info, Min_Dist_Calc  \n",
    "from Top_Opt_RL.DQN.Matrix_Transforms import obs_flip, action_flip, Mesh_Transform, Mesh_Triming \n",
    "from Top_Opt_RL.DQN.RL_Necessities import Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to plot learning curve\n",
    "dependancy: matplotlib\n",
    "input: x (Episode number), y (Average Reward), filename (name of the file to save the plot)\n",
    "output: none\n",
    "'''\n",
    "def plot_learning_curve(x, scores, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    running_average = np.zeros(len(scores))\n",
    "    for i in range(len(scores)):\n",
    "        running_average[i] = np.mean(scores[max(0, i-50):(i+1)])\n",
    "    \n",
    "    plt.title('Running average of previous 100 scores')    \n",
    "    ax.plot(x, running_average, color=\"blue\")\n",
    "    ax.set_xlabel(\"Episodes\", color=\"black\")\n",
    "    ax.set_ylabel(\"Average Reward\", color=\"black\")\n",
    "    ax.tick_params(axis='x', colors=\"black\")\n",
    "    ax.tick_params(axis='y', colors=\"black\")\n",
    "\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# test of the plot_learning_curve function\n",
    "# x = [i+1 for i in range(100)]\n",
    "# y = [i+1 for i in range(100)]\n",
    "# plot_learning_curve(x, y, \"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function stores the data history \n",
    "'''\n",
    "def Data_History(score_history, per_history, succ_history, Loss_history, Total_Loss, score, Main_EX, Main_EY,i):\n",
    "\n",
    "    Loss_history.append(Total_Loss)\n",
    "    avg_Loss=np.mean(Loss_history[-50:])\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-50:])\n",
    "    Succ_Steps=list(env.VoidCheck).count(0)\n",
    "    succ_history.append(Succ_Steps)\n",
    "\n",
    "    avg_succ = np.mean(succ_history[-50:])\n",
    "    Percent_Succ=Succ_Steps/(Main_EX*Main_EY)\n",
    "    per_history.append(Percent_Succ)\n",
    "    avg_percent=np.mean(per_history[-50:])\n",
    "    return score_history,per_history,succ_history,Loss_history,Succ_Steps,Percent_Succ,avg_succ,avg_score,avg_Loss,avg_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This is the main topopt function\n",
    "'''\n",
    "\n",
    "def TopOpt_Designing(User_Conditions, opts, envs): #,my_call_back_functions):\n",
    "    Time_Trial = opts.Time_Trial\n",
    "    if opts.Progressive_Refinement:\n",
    "        agent_primer= Agent(envs.env_primer,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR_EX)+'by'+str(opts.PR_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR_EX,EY=opts.PR_EY, n_actions=opts.PR_EX*opts.PR_EY,\n",
    "                            epsilon=0,input_dims=[opts.PR_EX,opts.PR_EY,3])\n",
    "                            \n",
    "        agent_primer2= Agent(envs.env_primer2,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR2_EX)+'by'+str(opts.PR2_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR2_EX,EY=opts.PR2_EY, n_actions=opts.PR2_EX*opts.PR2_EY, \n",
    "                            epsilon=0,input_dims=[opts.PR2_EX,opts.PR2_EY,3])\n",
    "        agent_primer.load_models()\n",
    "        agent_primer2.load_models()\n",
    "    \n",
    "    agent = Agent(envs.env,opts,Increase=False,filename_save=opts.filename_save+str(opts.Main_EX)+'by'+str(opts.Main_EY),\n",
    "                  filename_load=opts.filename_load,EX=opts.Main_EX,EY=opts.Main_EY, n_actions=opts.Main_EX*opts.Main_EY, \n",
    "                  epsilon=1.0, input_dims=[opts.Main_EX,opts.Main_EY,3])\n",
    "    if opts.Load_Checkpoints: agent.load_models()    \n",
    "    figure_file = 'plots/' + opts.filename_save +'_reward.png'    \n",
    "    best_score = envs.env.reward_range[0]    \n",
    "    score_history ,per_history,succ_history,Loss_history= [],[],[],[]\n",
    "    \n",
    "    if not opts.Load_Checkpoints:\n",
    "        from pandas import DataFrame \n",
    "        TrialData=DataFrame(columns=['Episode','Reward','Successfull Steps','Percent Successful','Avg Loss','SDEV','Epsilon','Time'])\n",
    "    envs.env.reset_conditions()\n",
    "    if opts.From_App:  opts.n_games=1\n",
    "    for i in range(opts.n_games):\n",
    "        Testing = False #Used to render the environment and track learning of the agent \n",
    "        if opts.Load_Checkpoints:\n",
    "            'If the user wants to test the agent, the user will be prompted to input BC and LC elements'\n",
    "            if opts.From_App:  App_Inputs(envs.env,envs.env_primer,envs.env_primer2,opts,User_Conditions)\n",
    "\n",
    "            else:  User_Inputs(envs.env,opts)\n",
    "\n",
    "        done = False\n",
    "        score = 0    \n",
    "        if i%10==0 and i>=100:\n",
    "            Testing=True\n",
    "            if i%200==0:\n",
    "                'Every 200 episodes, a special BC/LC will be used for monitoring purposes'\n",
    "                Testing_Inputs(envs.env,opts)\n",
    "                print('--------Testing Run------')\n",
    "        envs.env.VoidCheck=list(np.ones((1,envs.env.EX*envs.env.EY))[0])\n",
    "        if Time_Trial:     Start_Time_Trial=time.perf_counter()\n",
    "        observation = envs.env.reset()\n",
    "        print(envs.env)\n",
    "        if opts.Progressive_Refinement:\n",
    "            ''' Set Up to Complete 3 Iterations of Progressive Refinement'''\n",
    "            #Progressive Refinement #1 Going from Smallest to Intermediate Mesh Size\n",
    "            envs.env_primer.VoidCheck=list(np.ones((1,envs.env_primer.EX*envs.env_primer.EY))[0])\n",
    "            Prog_Refine_Act(agent_primer,envs.env,envs.env_primer,opts.Load_Checkpoints,Testing,opts,opts.PR_EX,opts.PR_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #Progressive Refinement #2 Going for Intermediate to Final Mesh Size\n",
    "            envs.env_primer2.VoidCheck=Mesh_Transform(opts.PR_EX,opts.PR_EY,opts.PR2_EX,opts.PR2_EY,envs.env_primer.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer\n",
    "            Prog_Refine_Act(agent_primer2,envs.env,envs.env_primer2,opts.Load_Checkpoints,Testing,opts,opts.PR2_EX,opts.PR2_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #This outcome will now be used as the final mesh Size \n",
    "            envs.env.VoidCheck=Mesh_Transform(opts.PR2_EX,opts.PR2_EY,opts.Main_EX,opts.Main_EY,envs.env_primer2.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer2\n",
    "            #Removed_Num=Mesh_Triming(env_primer,PR_EX,PR_EY)\n",
    "            #Uncomment the above line if you want to incorporate mesh trimming\n",
    "\n",
    "            observation[:,:,0]=np.reshape(FEASolve(envs.env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,envs.env.LC_Nodes,envs.env.Load_Directions,envs.env.BC_Nodes,Stress=True)[3],(opts.Main_EX,opts.Main_EY))\n",
    "        observation_v, observation_h,observation_vh=obs_flip(observation,opts.Main_EX,opts.Main_EY)\n",
    "        Last_Reward=0\n",
    "        while not done:\n",
    "            if i%1000==0 and i>=1: #Every 1000 iterations, show the activation maps\n",
    "                from keract import get_activations, display_activations \n",
    "                activations = get_activations(agent.q_eval.model, observation.reshape(-1,opts.Main_EX,opts.Main_EY,3))\n",
    "                display_activations(activations, save=False)\n",
    "            action = agent.choose_action(observation,opts.Load_Checkpoints,Testing)\n",
    "            observation_, reward, done, It= envs.env.step(action,observation,Last_Reward,opts.Load_Checkpoints,envs.env,FEA_Skip=1,PR=False)\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v_,observation_h_,observation_vh_=obs_flip(observation_,opts.Main_EX,opts.Main_EY)\n",
    "                action_v,action_h,action_vh=action_flip(action,opts.Main_EX,opts.Main_EY)\n",
    "                agent.store_transition(observation,action,reward,observation_,done)\n",
    "                agent.store_transition(observation_v,action_v,reward,observation_v_,done)\n",
    "                agent.store_transition(observation_h,action_h,reward,observation_h_,done)\n",
    "                agent.store_transition(observation_vh,action_vh,reward,observation_vh_,done)\n",
    "            score += reward\n",
    "            App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "            # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "            Last_Reward=reward\n",
    "            if Testing and not Time_Trial:\n",
    "                envs.env.render()\n",
    "                print('Current Score: '+str(round(score,3)))\n",
    "            observation = observation_\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v=observation_v_\n",
    "                observation_h=observation_h_\n",
    "                observation_vh=observation_vh_\n",
    "            if opts.Load_Checkpoints and not Time_Trial:   envs.env.render()\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "        # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "        return App_Plot        \n",
    "        toc=time.perf_counter()\n",
    "\n",
    "        if Time_Trial and not opts.From_App:\n",
    "            print('It took '+str(round(toc-Start_Time_Trial,1))+' seconds to complete this time trial.')    \n",
    "\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' RL environment class'''\n",
    "class EnviromentsRL:\n",
    "    def __init__(self, opts):\n",
    "        if opts.Load_Checkpoints:\n",
    "            SC=opts.SC\n",
    "            if opts.VF_S==0 and opts.From_App: #If the user wants to set a final volume fraction, set the intermediate volume fractions accordingly\n",
    "                Vol_Frac_2=opts.Vol_Frac_2\n",
    "                Vol_Frac_1=opts.Vol_Frac_1\n",
    "                Vol_Frac_3=opts.Vol_Frac_3 \n",
    "        else:\n",
    "            Vol_Frac_3=opts.Vol_Frac_3\n",
    "            Vol_Frac_1=opts.Vol_Frac_1\n",
    "            Vol_Frac_2=opts.Vol_Frac_2\n",
    "        self.env = TopOpt_Gen(opts.Main_EX,opts.Main_EY,Vol_Frac_3,SC,opts)\n",
    "        self.env_primer= TopOpt_Gen(opts.PR_EX,opts.PR_EY,Vol_Frac_1,SC,opts)\n",
    "        self.env_primer2=TopOpt_Gen(opts.PR2_EX,opts.PR2_EY,Vol_Frac_2,SC,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for Topology Optimization Options\n",
    "'''\n",
    "class Top_Options:\n",
    "    def __init__(self, Main_EX=24, Main_EY=24, PR2_EX=12, PR2_EY=12, PR_EX=6, PR_EY=6, Lx=1, Ly=1, Eta=2, a=5, b=5, replace=100, epsilon_dec=3.5e-4, eps_end=0.01, mem_size=30000, n_games=50000, batch_size=128, lr=5e-3, gamma=0.1, Vol_Frac_1=0.7, Vol_Frac_2=0.5, Vol_Frac_3=0.25, SC=10, P_Norm=10, filename_save='DDQN_TopOpt_Generalized_CNN_4L', filename_load='DDQN_TopOpt_Generalized_CNN_4L_6by6', Progressive_Refinement=True, LC=False, Load_Checkpoints=True, VF_S=0, Min_Dist=0, Time_Trial=True, configfile='config.json', From_App=True, base_folder=\".\"):\n",
    "        self.Main_EX = Main_EX  # Number of X Elements for Larger Environment\n",
    "        self.Main_EY = Main_EY  # Number of Y Elements for Larger Environment\n",
    "        self.PR2_EX = PR2_EX  # Number of X Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR2_EY = PR2_EY  # Number of Y Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR_EX = PR_EX  # Number of X Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.PR_EY = PR_EY  # Number of Y Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.Lx = Lx  # Length of the Structure in the X Direction\n",
    "        self.Ly = Ly  # Length of the Structure in the Y Direction\n",
    "        self.Eta = Eta  # Used for dynamic adjusting reward function. Larger eta means less prevalence given towards changes between current and previous reward. Recommend using [2,4]\n",
    "        self.a = a  # X Coefficient of the Quadratic Reward Surface\n",
    "        self.b = b  # Y Coefficient of the Quadratic Reward Surface\n",
    "        self.replace = replace  # Number of iterations between switching the weights from the active network to the target network\n",
    "        self.epsilon_dec = epsilon_dec  # Iterative decay amount of the epsilon value used for exploration/explotation\n",
    "        self.eps_end = eps_end  # Smallest Allowable Epsilon value to be used for exploration/explotation\n",
    "        self.mem_size = mem_size  # Size of the Replay Buffer\n",
    "        self.n_games = n_games  # Maximum Number of Training Episodes Conducted\n",
    "        self.batch_size = batch_size  # Batch Size that will be taken from the Replay Buffer per training episode\n",
    "        self.lr = lr  # Starting Learning Rate for the Network\n",
    "        self.gamma = gamma  # Discount Factor for Future Rewards\n",
    "        self.Vol_Frac_1 = Vol_Frac_1  # Volume Fraction during first progressive refinement\n",
    "        self.Vol_Frac_2 = Vol_Frac_2  # Final Volume Fraction\n",
    "        self.Vol_Frac_3 = Vol_Frac_3  # Final Volume Fraction\n",
    "        self.SC = SC  # Stress constraint, between 0 and 2\n",
    "        self.P_Norm = P_Norm  # Smoothing Parameter for P-Norm Global Stress calculation\n",
    "        self.filename_save = filename_save  # When training, what name would you like your weights, and figure saved as\n",
    "        self.filename_load = filename_load  # When testing, what name is your NN weights saved under\n",
    "        self.Progressive_Refinement = Progressive_Refinement\n",
    "        self.LC = LC # type in loading conditions manually\n",
    "        self.Load_Checkpoints = Load_Checkpoints\n",
    "        self.VF_S = VF_S # Use vol fraction constraint [0] or stress constraint [1]\n",
    "        self.Min_Dist = Min_Dist # The 0 value serves as a place holder to represent the minimum distance between the bounded and loaded elements in a given load case\n",
    "        self.Time_Trial = Time_Trial # Perform Time Trial\n",
    "        self.configfile = configfile # name of config file. \n",
    "        self.From_App = From_App # True if being called by an external app. Not sure this is needed. \"\n",
    "        self.base_folder = base_folder # Folder where to find saved files. Helpful if not running the app from the main folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading models ...\n",
      "... loading models ...\n",
      "... loading models ...\n",
      "<TopOpt_Gen instance>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'read_app_data' from '/home/csmd_chung/jupyter_projects/Top_Opt_RL/DQN/read_app_data.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = Top_Options()\n",
    "User_Conditions = json.load(open(opts.configfile) ) if opts.From_App else None  \n",
    "opts = Top_Options()\n",
    "envs = EnviromentsRL(opts)  \n",
    "App_Plot=TopOpt_Designing(User_Conditions,opts, envs)\n",
    "json.dump( App_Plot, open( \"App_Data.json\", 'w' ) )\n",
    "import read_app_data\n",
    "read_app_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksme2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2d8cee5fdffea191b801dc9e68000897c9e94bb15de5fb178821519dcf1f383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
