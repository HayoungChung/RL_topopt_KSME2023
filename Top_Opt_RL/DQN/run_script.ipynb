{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This is the main script to run the DQN algorithm. '''\n",
    "import os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(\"run_script.ipynb\"))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary modules\n",
    "from Top_Opt_RL.DQN.FEA_SOLVER_GENERAL import *\n",
    "from Top_Opt_RL.DQN.opts import parse_opts\n",
    "from Top_Opt_RL.DQN.TopOpt_Env_Functions import TopOpt_Gen, Prog_Refine_Act,User_Inputs,App_Inputs, Testing_Inputs, Testing_Info, Min_Dist_Calc  \n",
    "from Top_Opt_RL.DQN.Matrix_Transforms import obs_flip, action_flip, Mesh_Transform, Mesh_Triming \n",
    "from Top_Opt_RL.DQN.RL_Necessities import Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to plot learning curve\n",
    "dependancy: matplotlib\n",
    "input: x (Episode number), y (Average Reward), filename (name of the file to save the plot)\n",
    "output: none\n",
    "'''\n",
    "def plot_learning_curve(x, scores, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    running_average = np.zeros(len(scores))\n",
    "    for i in range(len(scores)):\n",
    "        running_average[i] = np.mean(scores[max(0, i-50):(i+1)])\n",
    "    \n",
    "    plt.title('Running average of previous 100 scores')    \n",
    "    ax.plot(x, running_average, color=\"blue\")\n",
    "    ax.set_xlabel(\"Episodes\", color=\"black\")\n",
    "    ax.set_ylabel(\"Average Reward\", color=\"black\")\n",
    "    ax.tick_params(axis='x', colors=\"black\")\n",
    "    ax.tick_params(axis='y', colors=\"black\")\n",
    "\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# test of the plot_learning_curve function\n",
    "# x = [i+1 for i in range(100)]\n",
    "# y = [i+1 for i in range(100)]\n",
    "# plot_learning_curve(x, y, \"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function stores the data history \n",
    "'''\n",
    "def Data_History(score_history, per_history, succ_history, Loss_history, Total_Loss, score, Main_EX, Main_EY,i):\n",
    "\n",
    "    Loss_history.append(Total_Loss)\n",
    "    avg_Loss=np.mean(Loss_history[-50:])\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-50:])\n",
    "    Succ_Steps=list(env.VoidCheck).count(0)\n",
    "    succ_history.append(Succ_Steps)\n",
    "\n",
    "    avg_succ = np.mean(succ_history[-50:])\n",
    "    Percent_Succ=Succ_Steps/(Main_EX*Main_EY)\n",
    "    per_history.append(Percent_Succ)\n",
    "    avg_percent=np.mean(per_history[-50:])\n",
    "    return score_history,per_history,succ_history,Loss_history,Succ_Steps,Percent_Succ,avg_succ,avg_score,avg_Loss,avg_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This is the main topopt function\n",
    "'''\n",
    "\n",
    "def TopOpt_Designing(User_Conditions, opts, envs): #,my_call_back_functions):\n",
    "    Time_Trial = opts.Time_Trial\n",
    "    if opts.Progressive_Refinement:\n",
    "        agent_primer= Agent(envs.env_primer,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR_EX)+'by'+str(opts.PR_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR_EX,EY=opts.PR_EY, n_actions=opts.PR_EX*opts.PR_EY,\n",
    "                            epsilon=0,input_dims=[opts.PR_EX,opts.PR_EY,3])\n",
    "                            \n",
    "        agent_primer2= Agent(envs.env_primer2,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR2_EX)+'by'+str(opts.PR2_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR2_EX,EY=opts.PR2_EY, n_actions=opts.PR2_EX*opts.PR2_EY, \n",
    "                            epsilon=0,input_dims=[opts.PR2_EX,opts.PR2_EY,3])\n",
    "        agent_primer.load_models()\n",
    "        agent_primer2.load_models()\n",
    "    \n",
    "    agent = Agent(envs.env,opts,Increase=False,filename_save=opts.filename_save+str(opts.Main_EX)+'by'+str(opts.Main_EY),\n",
    "                  filename_load=opts.filename_load,EX=opts.Main_EX,EY=opts.Main_EY, n_actions=opts.Main_EX*opts.Main_EY, \n",
    "                  epsilon=1.0, input_dims=[opts.Main_EX,opts.Main_EY,3])\n",
    "    if opts.Load_Checkpoints: agent.load_models()    \n",
    "    figure_file = 'plots/' + opts.filename_save +'_reward.png'    \n",
    "    best_score = envs.env.reward_range[0]    \n",
    "    score_history ,per_history,succ_history,Loss_history= [],[],[],[]\n",
    "    \n",
    "    if not opts.Load_Checkpoints:\n",
    "        from pandas import DataFrame \n",
    "        TrialData=DataFrame(columns=['Episode','Reward','Successfull Steps','Percent Successful','Avg Loss','SDEV','Epsilon','Time'])\n",
    "    envs.env.reset_conditions()\n",
    "    if opts.From_App:  opts.n_games=1\n",
    "    for i in range(opts.n_games):\n",
    "        Testing = False #Used to render the environment and track learning of the agent \n",
    "        if opts.Load_Checkpoints:\n",
    "            'If the user wants to test the agent, the user will be prompted to input BC and LC elements'\n",
    "            if opts.From_App:  App_Inputs(envs.env,envs.env_primer,envs.env_primer2,opts,User_Conditions)\n",
    "\n",
    "            else:  User_Inputs(envs.env,opts)\n",
    "\n",
    "        done = False\n",
    "        score = 0    \n",
    "        if i%10==0 and i>=100:\n",
    "            Testing=True\n",
    "            if i%200==0:\n",
    "                'Every 200 episodes, a special BC/LC will be used for monitoring purposes'\n",
    "                Testing_Inputs(envs.env,opts)\n",
    "                print('--------Testing Run------')\n",
    "        envs.env.VoidCheck=list(np.ones((1,envs.env.EX*envs.env.EY))[0])\n",
    "        if Time_Trial:     Start_Time_Trial=time.perf_counter()\n",
    "        observation = envs.env.reset()\n",
    "        print(envs.env)\n",
    "        if opts.Progressive_Refinement:\n",
    "            ''' Set Up to Complete 3 Iterations of Progressive Refinement'''\n",
    "            #Progressive Refinement #1 Going from Smallest to Intermediate Mesh Size\n",
    "            envs.env_primer.VoidCheck=list(np.ones((1,envs.env_primer.EX*envs.env_primer.EY))[0])\n",
    "            Prog_Refine_Act(agent_primer,envs.env,envs.env_primer,opts.Load_Checkpoints,Testing,opts,opts.PR_EX,opts.PR_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #Progressive Refinement #2 Going for Intermediate to Final Mesh Size\n",
    "            envs.env_primer2.VoidCheck=Mesh_Transform(opts.PR_EX,opts.PR_EY,opts.PR2_EX,opts.PR2_EY,envs.env_primer.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer\n",
    "            Prog_Refine_Act(agent_primer2,envs.env,envs.env_primer2,opts.Load_Checkpoints,Testing,opts,opts.PR2_EX,opts.PR2_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #This outcome will now be used as the final mesh Size \n",
    "            envs.env.VoidCheck=Mesh_Transform(opts.PR2_EX,opts.PR2_EY,opts.Main_EX,opts.Main_EY,envs.env_primer2.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer2\n",
    "            #Removed_Num=Mesh_Triming(env_primer,PR_EX,PR_EY)\n",
    "            #Uncomment the above line if you want to incorporate mesh trimming\n",
    "\n",
    "            observation[:,:,0]=np.reshape(FEASolve(envs.env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,envs.env.LC_Nodes,envs.env.Load_Directions,envs.env.BC_Nodes,Stress=True)[3],(opts.Main_EX,opts.Main_EY))\n",
    "        observation_v, observation_h,observation_vh=obs_flip(observation,opts.Main_EX,opts.Main_EY)\n",
    "        Last_Reward=0\n",
    "        while not done:\n",
    "            if i%1000==0 and i>=1: #Every 1000 iterations, show the activation maps\n",
    "                from keract import get_activations, display_activations \n",
    "                activations = get_activations(agent.q_eval.model, observation.reshape(-1,opts.Main_EX,opts.Main_EY,3))\n",
    "                display_activations(activations, save=False)\n",
    "            action = agent.choose_action(observation,opts.Load_Checkpoints,Testing)\n",
    "            observation_, reward, done, It= envs.env.step(action,observation,Last_Reward,opts.Load_Checkpoints,envs.env,FEA_Skip=1,PR=False)\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v_,observation_h_,observation_vh_=obs_flip(observation_,opts.Main_EX,opts.Main_EY)\n",
    "                action_v,action_h,action_vh=action_flip(action,opts.Main_EX,opts.Main_EY)\n",
    "                agent.store_transition(observation,action,reward,observation_,done)\n",
    "                agent.store_transition(observation_v,action_v,reward,observation_v_,done)\n",
    "                agent.store_transition(observation_h,action_h,reward,observation_h_,done)\n",
    "                agent.store_transition(observation_vh,action_vh,reward,observation_vh_,done)\n",
    "            score += reward\n",
    "            App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "            # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "            Last_Reward=reward\n",
    "            if Testing and not Time_Trial:\n",
    "                envs.env.render()\n",
    "                print('Current Score: '+str(round(score,3)))\n",
    "            observation = observation_\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v=observation_v_\n",
    "                observation_h=observation_h_\n",
    "                observation_vh=observation_vh_\n",
    "            if opts.Load_Checkpoints and not Time_Trial:   envs.env.render()\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "        # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "        return App_Plot        \n",
    "        toc=time.perf_counter()\n",
    "\n",
    "        if Time_Trial and not opts.From_App:\n",
    "            print('It took '+str(round(toc-Start_Time_Trial,1))+' seconds to complete this time trial.')    \n",
    "\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' RL environment class'''\n",
    "class EnviromentsRL:\n",
    "    def __init__(self, opts):\n",
    "        if opts.Load_Checkpoints:\n",
    "            SC=opts.SC\n",
    "            if opts.VF_S==0 and opts.From_App: #If the user wants to set a final volume fraction, set the intermediate volume fractions accordingly\n",
    "                Vol_Frac_2=opts.Vol_Frac_2\n",
    "                Vol_Frac_1=opts.Vol_Frac_1\n",
    "                Vol_Frac_3=opts.Vol_Frac_3 \n",
    "        else:\n",
    "            Vol_Frac_3=opts.Vol_Frac_3\n",
    "            Vol_Frac_1=opts.Vol_Frac_1\n",
    "            Vol_Frac_2=opts.Vol_Frac_2\n",
    "        self.env = TopOpt_Gen(opts.Main_EX,opts.Main_EY,Vol_Frac_3,SC,opts)\n",
    "        self.env_primer= TopOpt_Gen(opts.PR_EX,opts.PR_EY,Vol_Frac_1,SC,opts)\n",
    "        self.env_primer2=TopOpt_Gen(opts.PR2_EX,opts.PR2_EY,Vol_Frac_2,SC,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for Topology Optimization Options\n",
    "'''\n",
    "class Top_Options:\n",
    "    def __init__(self, Main_EX=24, Main_EY=24, PR2_EX=12, PR2_EY=12, PR_EX=6, PR_EY=6, Lx=1, Ly=1, Eta=2, a=5, b=5, replace=100, epsilon_dec=3.5e-4, eps_end=0.01, mem_size=30000, n_games=50000, batch_size=128, lr=5e-3, gamma=0.1, Vol_Frac_1=0.7, Vol_Frac_2=0.5, Vol_Frac_3=0.25, SC=10, P_Norm=10, filename_save='DDQN_TopOpt_Generalized_CNN_4L', filename_load='DDQN_TopOpt_Generalized_CNN_4L_6by6', Progressive_Refinement=True, LC=False, Load_Checkpoints=True, VF_S=0, Min_Dist=0, Time_Trial=True, configfile='config.json', From_App=True, base_folder=\".\"):\n",
    "        self.Main_EX = Main_EX  # Number of X Elements for Larger Environment\n",
    "        self.Main_EY = Main_EY  # Number of Y Elements for Larger Environment\n",
    "        self.PR2_EX = PR2_EX  # Number of X Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR2_EY = PR2_EY  # Number of Y Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR_EX = PR_EX  # Number of X Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.PR_EY = PR_EY  # Number of Y Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.Lx = Lx  # Length of the Structure in the X Direction\n",
    "        self.Ly = Ly  # Length of the Structure in the Y Direction\n",
    "        self.Eta = Eta  # Used for dynamic adjusting reward function. Larger eta means less prevalence given towards changes between current and previous reward. Recommend using [2,4]\n",
    "        self.a = a  # X Coefficient of the Quadratic Reward Surface\n",
    "        self.b = b  # Y Coefficient of the Quadratic Reward Surface\n",
    "        self.replace = replace  # Number of iterations between switching the weights from the active network to the target network\n",
    "        self.epsilon_dec = epsilon_dec  # Iterative decay amount of the epsilon value used for exploration/explotation\n",
    "        self.eps_end = eps_end  # Smallest Allowable Epsilon value to be used for exploration/explotation\n",
    "        self.mem_size = mem_size  # Size of the Replay Buffer\n",
    "        self.n_games = n_games  # Maximum Number of Training Episodes Conducted\n",
    "        self.batch_size = batch_size  # Batch Size that will be taken from the Replay Buffer per training episode\n",
    "        self.lr = lr  # Starting Learning Rate for the Network\n",
    "        self.gamma = gamma  # Discount Factor for Future Rewards\n",
    "        self.Vol_Frac_1 = Vol_Frac_1  # Volume Fraction during first progressive refinement\n",
    "        self.Vol_Frac_2 = Vol_Frac_2  # Final Volume Fraction\n",
    "        self.Vol_Frac_3 = Vol_Frac_3  # Final Volume Fraction\n",
    "        self.SC = SC  # Stress constraint, between 0 and 2\n",
    "        self.P_Norm = P_Norm  # Smoothing Parameter for P-Norm Global Stress calculation\n",
    "        self.filename_save = filename_save  # When training, what name would you like your weights, and figure saved as\n",
    "        self.filename_load = filename_load  # When testing, what name is your NN weights saved under\n",
    "        self.Progressive_Refinement = Progressive_Refinement\n",
    "        self.LC = LC # type in loading conditions manually\n",
    "        self.Load_Checkpoints = Load_Checkpoints\n",
    "        self.VF_S = VF_S # Use vol fraction constraint [0] or stress constraint [1]\n",
    "        self.Min_Dist = Min_Dist # The 0 value serves as a place holder to represent the minimum distance between the bounded and loaded elements in a given load case\n",
    "        self.Time_Trial = Time_Trial # Perform Time Trial\n",
    "        self.configfile = configfile # name of config file. \n",
    "        self.From_App = From_App # True if being called by an external app. Not sure this is needed. \"\n",
    "        self.base_folder = base_folder # Folder where to find saved files. Helpful if not running the app from the main folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading models ...\n",
      "... loading models ...\n",
      "... loading models ...\n",
      "<TopOpt_Gen instance>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'read_app_data' from '/home/csmd_chung/jupyter_projects/RL_topopt_KSME2023/Top_Opt_RL/DQN/read_app_data.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = Top_Options()\n",
    "User_Conditions = json.load(open(opts.configfile) ) if opts.From_App else None  \n",
    "opts = Top_Options()\n",
    "envs = EnviromentsRL(opts)  \n",
    "App_Plot=TopOpt_Designing(User_Conditions,opts, envs)\n",
    "json.dump( App_Plot, open( \"App_Data.json\", 'w' ) )\n",
    "import read_app_data\n",
    "read_app_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksme2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2d8cee5fdffea191b801dc9e68000897c9e94bb15de5fb178821519dcf1f383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
